@article{Bhattacharya2011,
	abstract = {We focus on sparse modelling of high-dimensional covariance matrices using Bayesian latent factor models. We propose a multiplicative gamma process shrinkage prior on the factor loadings which allows introduction of infinitely many factors, with the loadings increasingly shrunk towards zero as the column index increases. We use our prior on a parameter-expanded loading matrix to avoid the order dependence typical in factor analysis models and develop an efficient Gibbs sampler that scales well as data dimensionality increases. The gain in efficiency is achieved by the joint conjugacy property of the proposed prior, which allows block updating of the loadings matrix. We propose an adaptive Gibbs sampler for automatically truncating the infinite loading matrix through selection of the number of important factors. Theoretical results are provided on the support of the prior and truncation approximation bounds. A fast algorithm is proposed to produce approximate Bayes estimates. Latent factor regression methods are developed for prediction and variable selection in applications with high-dimensional correlated predictors. Operating characteristics are assessed through simulation studies, and the approach is applied to predict survival times from gene expression data.},
	author = {Bhattacharya, A. and Dunson, D. B.},
	doi = {10.1093/biomet/asr013},
	file = {:C$\backslash$:/Users/Windows/Documents/Claire IMIFA/Papers {\&} Books/BhattacharyaDunson.pdf:pdf},
	issn = {00063444},
	journal = {Biometrika},
	keywords = {Adaptive Gibbs sampling,Factor analysis,High-dimensional data,Multiplicative gamma process,Parameter expansion,Regularization,Shrinkage},
	mendeley-groups = {IMIFA},
	number = {2},
	pages = {291--306},
	pmid = {23049129},
	title = {\textit{Sparse Bayesian infinite factor models}},
	volume = {98},
	year = {2011}
}

@book{GMRFbook,
	AUTHOR = {H. Rue and L. Held},
	TITLE = {Gaussian {M}arkov Random Fields: {T}heory and Applications},
	SERIES = {Monographs on Statistics and Applied Probability},
	VOLUME = {104},
	PUBLISHER = {Chapman \& Hall},
	ADDRESS = {London},
	YEAR = 2005
}

@book{Fruhwirth-Schnatter2010,
	author = {Fr{\"{u}}hwirth-Schnatter, S.},
	doi = {10.1007/978-0-387-98135-2},
	file = {:C$\backslash$:/Users/Windows/Documents/Claire IMIFA/Papers {\&} Books/[Fruhwirth-Schnatter] Finite Mixture and Markov Switching Models.pdf:pdf},
	isbn = {9780387775005},
	issn = {01727397},
	publisher = {Springer series in statistics},
	mendeley-groups = {TextBooks},
	pages = {1--656},
	pmid = {15772297},
	title = {{Finite Mixture and Markov Switching Models}},
	year = {2010}
}

@INBOOK{Fruhwirth-Schnatter2011,
	title = {Dealing with label switching under model uncertainty}, 
	author = {Fr{\"{u}}hwirth-Schnatter, S.},
	publisher = {Wiley},
	year = {2011},
	isbn = {ISBN-10: 11199938},
	address = {Chichester},
	publisher = {Wiley},
	language = {EN},
	pages = {193-218}, 
	series = {Mixture estimation and applications},
	abstract = {Statistical mixture distributions are used to model scenarios in which certain variables are measured but a categorical variable is missing. For example, although clinical data on a patient may be available their disease category may not be, and this adds significant degrees of complication to the statistical analysis. The above situation characterises the simplest mixture-type scenario; variations include, among others, hidden Markov models, in which the missing variable follows a Markov chain model, and latent structure models, in which the missing variable or variables represent model-enriching devices rather than real physical entities. In the title of the workshop the term `mixture' is taken to include these and other variations along with the simple mixture. The motivating factors for this three-day workshop are that research on inference and computational techniques for mixture-type models is currently experiencing major advances and that simultaneously the application of mixture modelling to many fields in science and elsewhere has never been so rich. We thus assembling top players, from statistics and computer science, in both methodological research and applied inference at this fertile interface. The methodological component will involve both Bayesian and non-Bayesian contributions and biology and economics will feature strongly among the application areas to be covered.},
}

@book{McLachlanPeel,
	title = "Finite mixture models",
	author = "McLachlan, G. J. and Peel, D.",
	series = "Wiley series in probability and statistics",
	publisher = "J. Wiley \& Sons",
	address = "New York",
	url = "http://opac.inria.fr/record=b1097397",
	isbn = "0471006262",
	year = 2000
}

@article{Raftery2007,
	abstract = {The integrated likelihood (also called the marginal likelihood or the normalizing constant) is a central quantity in Bayesian model selection and model averaging. It is defined as the integral over the parameter space of the likelihood times the prior density. The Bayes factor for model comparison and Bayesian testing is a ratio of integrated likelihoods, and the model weights in Bayesian model averaging are proportional to the integrated likelihoods. We consider the estimation of the integrated likelihood from posterior simulation output, aiming at a generic method that uses only the likelihoods from the posterior simulation iterations. The key is the harmonic mean identity, which says that the reciprocal of the integrated likelihood is equal to the posterior harmonic mean of the likelihood. The simplest estimator based on the identity is thus the harmonic mean of the likelihoods. While this is an unbiased and simulation-consistent estimator, its reciprocal can have infinite variance and so it is unstable in general. We describe two methods for stabilizing the harmonic mean estimator. In the first one, the parameter space is reduced in such a way that the modified estimator involves a harmonic mean of heavier-tailed densities, thus resulting in a finite variance estimator. The resulting estimator is stable. It is also self-monitoring, since it obeys the central limit theorem, and so confidence intervals are available. We discuss general conditions under which this reduction is applicable.},
	author = {Raftery, A. E. and  Newton, M. and Krivitsky, P. N. and Satagopan, J. M.},
	file = {:C$\backslash$:/Users/Windows/Documents/Claire IMIFA/Papers {\&} Books/Raftery-BICM.pdf:pdf},
	journal = {Bayesian Statistics},
	keywords = {Raftery2007},
	mendeley-groups = {IMIFA},
	number = {8},
	pages = {1--45},
	title = {{Estimating the Integrated Likelihood via Posterior Simulation Using the Harmonic Mean Identity}},
	year = {2007}
}